{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOyjDFH80JlqnS3Z+eWxJD+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aryan-401/GenAI-RNN/blob/master/Shakespeare_Type_Generation_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvuV9HHV0X5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ac6eb0-bae2-470b-c644-3ea001e00127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.3.6\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import string\n",
        "import random\n",
        "import sys\n",
        "!pip install Unidecode\n",
        "import unidecode\n",
        "from torchtext.utils import download_from_url\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCBJYTMO0twi",
        "outputId": "9c15c6d3-5199-4b1c-d634-10b675ee2036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "print(all_characters, n_characters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SirpRGCv1NyA",
        "outputId": "10849f22-587f-425d-8cad-38078aa656f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = download_from_url('https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt', './shakespeare.txt')\n",
        "file_shakespeare = unidecode.unidecode(open('./shakespeare.txt').read())"
      ],
      "metadata": {
        "id": "M5c8Y57y43yX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d0a002-ea0e-4f01-f2b2-691c8c4b9201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.12M/1.12M [00:00<00:00, 102MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embed = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first = True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        out = self.embed(x)\n",
        "        out, (hidden, cell)  = self.lstm(out.unsqueeze(1), (hidden, cell))\n",
        "        out = self.fc(out.reshape(out.shape[0], -1))\n",
        "        return out, (hidden, cell)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "        return hidden, cell"
      ],
      "metadata": {
        "id": "jNxmsXYt2F_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "class Generator():\n",
        "    def __init__(self):\n",
        "        self.chunk_len = 250\n",
        "        self.num_epochs = 5000\n",
        "        self.batch_size = 1\n",
        "        self.print_every = 200\n",
        "        self.hidden_size = 256\n",
        "        self.num_layers = 2\n",
        "        self.file = file_shakespeare\n",
        "        self.lr = 0.003\n",
        "\n",
        "    def char_tensor(self, string):\n",
        "        tensor = torch.zeros(len(string)).long()\n",
        "        for c in range(len(string)):\n",
        "            tensor[c] = all_characters.index(string[c])\n",
        "        return tensor\n",
        "\n",
        "    def get_random_batch(self):\n",
        "        start_index = random.randint(0, len(self.file) - self.chunk_len)\n",
        "        end_index = start_index + self.chunk_len + 1\n",
        "        text_str = self.file[start_index: end_index]\n",
        "        text_input = torch.zeros(self.batch_size, self.chunk_len)\n",
        "        text_target = torch.zeros(self.batch_size, self.chunk_len)\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            text_input[i,:] = self.char_tensor(text_str[:-1])\n",
        "            text_target[i,:] = self.char_tensor(text_str[1:])\n",
        "\n",
        "        return text_input.long(), text_target.long()\n",
        "\n",
        "    def generate(self, initial_string = 'A', prediction_len = 100, temprature = 1.0):\n",
        "        hidden, cell = self.rnn.init_hidden(batch_size=self.batch_size)\n",
        "        initial_input = self.char_tensor(initial_string)\n",
        "        predicted = initial_string\n",
        "\n",
        "        for p in range(len(initial_string) - 1):\n",
        "            _, (hidden, cell) = self.rnn(initial_input[p].view(1).to(device), hidden, cell)\n",
        "\n",
        "        last_char = initial_input[-1]\n",
        "\n",
        "        for p in range(prediction_len):\n",
        "            output, (hidden, cell) = self.rnn(last_char.view(1).to(device), hidden, cell)\n",
        "            output_dist = output.data.view(-1).div(temprature).exp()\n",
        "            top_char = torch.multinomial(output_dist, 1)[0]\n",
        "            predicted_char = all_characters[top_char]\n",
        "            if predicted_char == \"\\n\":\n",
        "                break\n",
        "            predicted += predicted_char\n",
        "            last_char = self.char_tensor(predicted_char)\n",
        "\n",
        "        return predicted\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        self.rnn = RNN(n_characters, self.hidden_size, self.num_layers, n_characters).to(device)\n",
        "        optimizer = torch.optim.Adam(self.rnn.parameters(), lr = self.lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        writer = SummaryWriter(f'runs/names0')\n",
        "\n",
        "        print(\"== Starting Training ==\")\n",
        "        for epoch in range(1, self.num_epochs + 1):\n",
        "            inp, target = self.get_random_batch()\n",
        "            hidden, cell = self.rnn.init_hidden(batch_size=self.batch_size)\n",
        "\n",
        "            self.rnn.zero_grad()\n",
        "            loss = 0\n",
        "            inp, target = inp.to(device), target.to(device)\n",
        "            for c in range(self.chunk_len):\n",
        "                output, (hidden, cell) = self.rnn(inp[:, c], hidden, cell)\n",
        "                loss += criterion(output, target[:, c])\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss = loss.item() / self.chunk_len\n",
        "\n",
        "            if epoch % self.print_every == 0:\n",
        "                print(f\"Epoch: {epoch}/ {self.num_epochs}| Loss: {loss}\")\n",
        "                torch.save(self.rnn.state_dict(), f'./shakespeare_model_{epoch}.pt')\n",
        "                print(self.generate())\n",
        "            writer.add_scalar(\"Training loss\", loss, global_step=epoch)\n",
        "\n",
        "        torch.save(self.rnn.state_dict(), './shakespeare_model.pt')\n",
        "\n",
        "    def get_model(self, model_name):\n",
        "        self.rnn = RNN(n_characters, self.hidden_size, self.num_layers, n_characters).to(device)\n",
        "        self.rnn.load_state_dict(torch.load(model_name))\n",
        "        self.rnn.eval()\n",
        "        return self.rnn"
      ],
      "metadata": {
        "id": "Niw85SKJ4cIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gennames = Generator()\n",
        "gennames.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36X86t8kCqPu",
        "outputId": "50a2354e-7f5f-406a-a570-5e75b2afed9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Starting Training ==\n",
            "Epoch: 200/ 5000| Loss: 2.139631103515625\n",
            "Acer and is hevent?\n",
            "\n",
            "EUCICSAS:\n",
            "I to the try, be net pressings then bey\n",
            "Ard wandtell.\n",
            "\n",
            "GENUTA:\n",
            "If my n\n",
            "Epoch: 400/ 5000| Loss: 1.7931781005859375\n",
            "APUIET:\n",
            "Of den calm te cagenglake ye, That both with gexous\n",
            "fove thet.\n",
            "\n",
            "Thed lied:\n",
            "Of malaping the so\n",
            "Epoch: 600/ 5000| Loss: 2.07499267578125\n",
            "Adder bat my woulsch me will king: oor -roguelswar breded.\n",
            "Musare!\n",
            "\n",
            "Sainks whet heress\n",
            "apin o fare hu\n",
            "Epoch: 800/ 5000| Loss: 1.647232666015625\n",
            "Awan thou super;\n",
            "This came ip'd seect of manessual shall sent pester swo itent-crake uncitenter minot\n",
            "Epoch: 1000/ 5000| Loss: 1.6970052490234375\n",
            "Aper, sep the;' are bife you that which made rook\n",
            "The part him repiefu should are:\n",
            "But fore for notke\n",
            "Epoch: 1200/ 5000| Loss: 1.8163983154296874\n",
            "AiT\n",
            "The contentery wasse wouce,\n",
            "But longs in thee a\n",
            "mous' weremn is somes of the gratturelt!\n",
            "\n",
            "Seemt; \n",
            "Epoch: 1400/ 5000| Loss: 1.7013272705078124\n",
            "ANNES:\n",
            "Naround is lade, right of bringes,\n",
            "And yet give not sincean: the never in not fer genteres.\n",
            "\n",
            "N\n",
            "Epoch: 1600/ 5000| Loss: 1.5932379150390625\n",
            "And:\n",
            "Ay, he's glag shall me me pack not: at come\n",
            "ne't Rom.\n",
            "\n",
            "JULIET:\n",
            "That sick to mutch the even thee \n",
            "Epoch: 1800/ 5000| Loss: 1.4023167724609376\n",
            "And\n",
            "Again'd, I look, gory as thret her in the rije.\n",
            "And his reford.\n",
            "\n",
            "FLORIZEL:\n",
            "We. What the haked you\n",
            "Epoch: 2000/ 5000| Loss: 1.6005545654296875\n",
            "ATHARINA:\n",
            "Nover to fine some to ring and him!\n",
            "\n",
            "SICIFOND:\n",
            "I bring his in the fielionly far her dead.\n",
            "N\n",
            "Epoch: 2200/ 5000| Loss: 1.57549072265625\n",
            "ALET:\n",
            "I pray once my Lord of jay,\n",
            "Bareds and day I heart Bongrace,\n",
            "And thing, liface, come: prestent \n",
            "Epoch: 2400/ 5000| Loss: 1.6373797607421876\n",
            "Adaust:\n",
            "Semull sform'd shy,\n",
            "Must, have ground him to maund my marsel'd;\n",
            "If fut ever ppousing.\n",
            "\n",
            "GLOW:\n",
            "\n",
            "Epoch: 2600/ 5000| Loss: 1.5392674560546875\n",
            "AUME:\n",
            "The bed: sir. Mits my the Edwiss: Farmtay, my more\n",
            "What the be to of ploose this dries' up,\n",
            "I b\n",
            "Epoch: 2800/ 5000| Loss: 1.5109794921875\n",
            "ANNIUS:\n",
            "Nor stire, why the nobless fresher to let; where Conwal,\n",
            "Who, you go all the deadver:\n",
            "Alaight\n",
            "Epoch: 3000/ 5000| Loss: 1.769095947265625\n",
            "A\\ENTIO:\n",
            "Some solder into in to match mine dot hass'd my footh unhere south\n",
            "En to that I before anfig\n",
            "Epoch: 3200/ 5000| Loss: 1.42495654296875\n",
            "Apon it wear the come me withse\n",
            "down Vome Guestal! But fellow Complease yet by the man\n",
            "Out go as farl\n",
            "Epoch: 3400/ 5000| Loss: 1.5379598388671876\n",
            "Ast your patch.\n",
            "Farewell, whell him to a pend-remaint of my wife, and with a rest smile;\n",
            "For confoure\n",
            "Epoch: 3600/ 5000| Loss: 1.4105281982421876\n",
            "At is both your degeral\n",
            "By son late, course.\n",
            "\n",
            "BENVOLIO:\n",
            "O, sir, I very execte.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "\n",
            "MENE\n",
            "Epoch: 3800/ 5000| Loss: 1.7288260498046875\n",
            "AWhals hold bether he shall goen monoursbight man\n",
            "For Hay Gauntou fons, and Pate,\n",
            "This fortune is you\n",
            "Epoch: 4000/ 5000| Loss: 1.3177645263671875\n",
            "Al and our loved in thinester\n",
            "Aufot hit the fing, thou may his isteet light inst in desiral eyes.\n",
            "All\n",
            "Epoch: 4200/ 5000| Loss: 1.8316832275390624\n",
            "ABRON:\n",
            "Destriucle mistast: tey the young my sound by\n",
            "suns; Michmaway, any ca'er when not upon or long\n",
            "Epoch: 4400/ 5000| Loss: 1.3747415771484375\n",
            "At and uslese the consorrows of it.\n",
            "But no equalt or take the determer-saves hear recomes;\n",
            "My basedy?\n",
            "Epoch: 4600/ 5000| Loss: 2.0505869140625\n",
            "ARD:\n",
            " My bear--fordil not timest, be fish and Petter,\n",
            "Within thy places. The love to me he by they th\n",
            "Epoch: 4800/ 5000| Loss: 1.387529296875\n",
            "Anglands, hath grown\n",
            "And my fanural. O not the common each of dead, pity.\n",
            "\n",
            "LARTIUS:\n",
            "\n",
            "ARIELIUS:\n",
            "Madam,\n",
            "Epoch: 5000/ 5000| Loss: 1.65001318359375\n",
            "AM, honour, and, my lords her regament.\n",
            "\n",
            "TRANIO:\n",
            "Then 'tis small.\n",
            "\n",
            "GLOUCESTER:\n",
            "Of a tought be young t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gennames.generate('I am God', 100, 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "f5u_kpCyIv92",
        "outputId": "d095f84c-ae6c-4ee8-b95a-7685075e7f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I am God the books and the wife the good thou that thou hold with me\\nAs the sure the true in thy stand and t'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gennames = Generator()"
      ],
      "metadata": {
        "id": "Quct1yxwb9pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gennames.get_model(\"shakespeare_model_4400.pt\")"
      ],
      "metadata": {
        "id": "M-luD_x_I4UB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9210a24c-b0f1-4d6e-f81e-35f708e772a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embed): Embedding(100, 256)\n",
              "  (lstm): LSTM(256, 256, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=256, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gennames.generate('I am God', 100, 0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hUFSPlYFb0iY",
        "outputId": "3451b906-e797-4135-e6e7-0c5e37ed03ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I am God the earth to at the house the death,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "T8TcbdVHcBYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gennames.generate(\"Ikshan Bhardwaj \", 100, 0.7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iTNNEGqDchXL",
        "outputId": "1293f105-7d26-487a-e9ef-63ec523631c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ikshan Bhardwaj hither.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1JVpqWmEdeDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}